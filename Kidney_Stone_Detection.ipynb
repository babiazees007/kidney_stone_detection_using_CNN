{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cafef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b03554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Path\n",
    "path = 'CT_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843005e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the images\n",
    "train_data_dir = os.path.join(path, 'Train')\n",
    "test_data_dir = os.path.join(path, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1828c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0c3ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 2 classes.\n",
      "Found 900 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb3babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Adding convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Adding a second convolutional layer\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())  # this converts our feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b4334bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3116fed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3714 - accuracy: 0.8504WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 32 batches). You may need to use the repeat() function when building your dataset.\n",
      "32/32 [==============================] - 21s 629ms/step - loss: 0.3714 - accuracy: 0.8504 - val_loss: 0.7621 - val_accuracy: 0.5989\n",
      "Epoch 2/46\n",
      "32/32 [==============================] - 11s 349ms/step - loss: 0.0437 - accuracy: 0.9873\n",
      "Epoch 3/46\n",
      "32/32 [==============================] - 11s 328ms/step - loss: 0.0178 - accuracy: 0.9961\n",
      "Epoch 4/46\n",
      "32/32 [==============================] - 10s 314ms/step - loss: 0.0083 - accuracy: 0.9990\n",
      "Epoch 5/46\n",
      "32/32 [==============================] - 10s 296ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 6/46\n",
      "32/32 [==============================] - 10s 295ms/step - loss: 0.0066 - accuracy: 0.9990\n",
      "Epoch 7/46\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 8/46\n",
      "32/32 [==============================] - 9s 289ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 9/46\n",
      "32/32 [==============================] - 10s 309ms/step - loss: 0.0025 - accuracy: 0.9990\n",
      "Epoch 10/46\n",
      "32/32 [==============================] - 10s 300ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 11/46\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 8.1111e-04 - accuracy: 1.0000\n",
      "Epoch 12/46\n",
      "32/32 [==============================] - 9s 286ms/step - loss: 7.8457e-04 - accuracy: 1.0000\n",
      "Epoch 13/46\n",
      "32/32 [==============================] - 9s 284ms/step - loss: 4.9846e-04 - accuracy: 1.0000\n",
      "Epoch 14/46\n",
      "32/32 [==============================] - 10s 295ms/step - loss: 4.7127e-04 - accuracy: 1.0000\n",
      "Epoch 15/46\n",
      "32/32 [==============================] - 9s 288ms/step - loss: 5.2391e-04 - accuracy: 1.0000\n",
      "Epoch 16/46\n",
      "32/32 [==============================] - 9s 284ms/step - loss: 4.3985e-04 - accuracy: 1.0000\n",
      "Epoch 17/46\n",
      "32/32 [==============================] - 9s 282ms/step - loss: 3.1706e-04 - accuracy: 1.0000\n",
      "Epoch 18/46\n",
      "32/32 [==============================] - 9s 280ms/step - loss: 8.1124e-05 - accuracy: 1.0000\n",
      "Epoch 19/46\n",
      "32/32 [==============================] - 9s 285ms/step - loss: 5.9818e-05 - accuracy: 1.0000\n",
      "Epoch 20/46\n",
      "32/32 [==============================] - 9s 282ms/step - loss: 6.0076e-05 - accuracy: 1.0000\n",
      "Epoch 21/46\n",
      "32/32 [==============================] - 9s 285ms/step - loss: 3.5554e-04 - accuracy: 1.0000\n",
      "Epoch 22/46\n",
      "32/32 [==============================] - 10s 297ms/step - loss: 9.7665e-05 - accuracy: 1.0000\n",
      "Epoch 23/46\n",
      "32/32 [==============================] - 9s 290ms/step - loss: 9.4005e-05 - accuracy: 1.0000\n",
      "Epoch 24/46\n",
      "32/32 [==============================] - 10s 294ms/step - loss: 1.8563e-05 - accuracy: 1.0000\n",
      "Epoch 25/46\n",
      "32/32 [==============================] - 9s 290ms/step - loss: 1.6346e-04 - accuracy: 1.0000\n",
      "Epoch 26/46\n",
      "32/32 [==============================] - 9s 290ms/step - loss: 0.0016 - accuracy: 0.9990\n",
      "Epoch 27/46\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "Epoch 28/46\n",
      "32/32 [==============================] - 9s 286ms/step - loss: 0.0136 - accuracy: 0.9951\n",
      "Epoch 29/46\n",
      "32/32 [==============================] - 9s 289ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 30/46\n",
      "32/32 [==============================] - 10s 297ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 31/46\n",
      "32/32 [==============================] - 10s 299ms/step - loss: 1.7994e-04 - accuracy: 1.0000\n",
      "Epoch 32/46\n",
      "32/32 [==============================] - 9s 291ms/step - loss: 4.7358e-04 - accuracy: 1.0000\n",
      "Epoch 33/46\n",
      "32/32 [==============================] - 10s 296ms/step - loss: 1.9911e-04 - accuracy: 1.0000\n",
      "Epoch 34/46\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 2.0621e-04 - accuracy: 1.0000\n",
      "Epoch 35/46\n",
      "32/32 [==============================] - 9s 290ms/step - loss: 5.1716e-04 - accuracy: 1.0000\n",
      "Epoch 36/46\n",
      "32/32 [==============================] - 9s 288ms/step - loss: 9.0304e-05 - accuracy: 1.0000\n",
      "Epoch 37/46\n",
      "32/32 [==============================] - 9s 291ms/step - loss: 3.2330e-04 - accuracy: 1.0000\n",
      "Epoch 38/46\n",
      "32/32 [==============================] - 10s 295ms/step - loss: 2.6130e-05 - accuracy: 1.0000\n",
      "Epoch 39/46\n",
      "32/32 [==============================] - 9s 286ms/step - loss: 3.4543e-05 - accuracy: 1.0000\n",
      "Epoch 40/46\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 5.9346e-05 - accuracy: 1.0000\n",
      "Epoch 41/46\n",
      "32/32 [==============================] - 9s 277ms/step - loss: 3.7519e-05 - accuracy: 1.0000\n",
      "Epoch 42/46\n",
      "32/32 [==============================] - 9s 284ms/step - loss: 2.0938e-05 - accuracy: 1.0000\n",
      "Epoch 43/46\n",
      "32/32 [==============================] - 9s 285ms/step - loss: 3.9843e-05 - accuracy: 1.0000\n",
      "Epoch 44/46\n",
      "32/32 [==============================] - 10s 312ms/step - loss: 4.2048e-05 - accuracy: 1.0000\n",
      "Epoch 45/46\n",
      "32/32 [==============================] - 10s 317ms/step - loss: 3.7952e-05 - accuracy: 1.0000\n",
      "Epoch 46/46\n",
      "32/32 [==============================] - 10s 309ms/step - loss: 2.7334e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df8a0b96c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=32,\n",
    "    epochs=46,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21414f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Model\n",
    "model.save('kidney_stone_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff385ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 148, 148, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 72, 72, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 41472)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2654272   \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,664,481\n",
      "Trainable params: 2,664,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c71cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 5s 159ms/step - loss: 1.3067 - accuracy: 0.8433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.306713342666626, 0.8433333039283752]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe5cc5",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45ae3d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required Modules\n",
    "import cv2 \n",
    "import numpy as np \n",
    "from skimage.feature import hog \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "761971dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to read images from the train and test folders\n",
    "def read_images(path):\n",
    "    images_list = []\n",
    "    for filename in os.listdir(path):\n",
    "        img = cv2.imread(os.path.join(path,filename))\n",
    "        if img is not None:\n",
    "            images_list.append(img)\n",
    "    return images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "118411cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading train images from the normal and stone folders\n",
    "train_normal = read_images('CT_images/Train/Normal')\n",
    "train_stone = read_images('CT_images/Train/Stone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa41bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of labels for training \n",
    "labels = ['Normal' for item in train_normal] + ['Stone' for item in train_stone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6abe13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function for HOG feature extraction\n",
    "def extract_features(images):\n",
    "    feature_list = []\n",
    "    for img in images:\n",
    "        fd, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16), \n",
    "                            cells_per_block=(1, 1), visualize=True, channel_axis=2)\n",
    "        # Resize the HOG features to a fixed size\n",
    "        fd = np.resize(fd, (2400, 1))\n",
    "        # Flatten the array to 2 dimensions\n",
    "        fd = fd.flatten()\n",
    "        feature_list.append(fd)\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f54dfc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the HOG features from both normal and stone images\n",
    "feature_list_normal = extract_features(train_normal)\n",
    "feature_list_stone = extract_features(train_stone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c27a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(feature_list_normal))\n",
    "print(len(feature_list_stone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b2b190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the features for both classes\n",
    "features = feature_list_normal + feature_list_stone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af3c553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading test images from the normal and stone folders\n",
    "test_normal = read_images('CT_images/Test/Normal')\n",
    "test_stone = read_images('CT_images/Test/Stone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43387cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of labels for testing \n",
    "test_labels = ['Normal' for item in test_normal] + ['Stone' for item in test_stone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce51341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Feature Vector for Test Set\n",
    "test_feature_list_normal = extract_features(test_normal)\n",
    "test_feature_list_stone = extract_features(test_stone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce8f22da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(test_feature_list_normal))\n",
    "print(len(test_feature_list_stone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13fe4306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the features for both classes\n",
    "test_features = test_feature_list_normal + test_feature_list_stone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9bd6770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train and valid sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b863d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400,)\n",
      "(2400,)\n",
      "(2400,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the first element in the X_train array\n",
    "print(X_train[0].shape)\n",
    "\n",
    "# Print the shape of the second element in the X_train array\n",
    "print(X_train[1].shape)\n",
    "\n",
    "# Print the shape of the last element in the X_train array\n",
    "print(X_train[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de1212b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma='auto')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training a SVM Model\n",
    "svc = SVC(kernel='rbf', C=1, gamma='auto')\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1465f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test Set\n",
    "y_pred = svc.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbbf0973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7966666666666666\n"
     ]
    }
   ],
   "source": [
    "#Calculating the accuracy\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(\"Accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ee1a7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.externals\n",
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(svc, 'svc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f50c18c",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc398d6e",
   "metadata": {},
   "source": [
    "## If you dont want to train the models you can load the models which I have already trained otherwise you can skip these loading models cell and directly run the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b3abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('kidney_stone_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0483c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.externals\n",
    "import joblib\n",
    "svc = joblib.load(\"svc.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd37c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Select Image\n",
    "def browse_btn():\n",
    "    global image_name\n",
    "    \n",
    "    label_cnn.configure(text=\"\")\n",
    "    label.configure(text=\"\")\n",
    "    \n",
    "    image_name = askopenfilename(title='Select Image')\n",
    "    img = Image.open(image_name)\n",
    "    img = img.resize((200, 200), Image.ANTIALIAS)\n",
    "    img = ImageTk.PhotoImage(img)\n",
    "    panel = tk.Label(root, image=img)\n",
    "    panel.image = img\n",
    "    panel.grid(row=0,column=1,sticky='nw',padx=20,pady=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5889a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Predict CNN\n",
    "def predict_btn_cnn():\n",
    "    global label_prediction\n",
    "    global image_name\n",
    "    test_img = image.load_img(image_name, target_size=(150, 150))\n",
    "    test_img = image.img_to_array(test_img)\n",
    "    test_img = np.expand_dims(test_img, axis=0)\n",
    "    result = model.predict(test_img)\n",
    "    if result[0][0] == 1:\n",
    "        label_cnn.configure(text=\"Kidney Stone Detected\")\n",
    "    elif result[0][0] == 0:\n",
    "        label_cnn.configure(text=\"No Kidney Stone Detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29e3fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Predict SVM        \n",
    "def predict_btn_svm():\n",
    "    global label_prediction\n",
    "    global image_name\n",
    "    test_img = cv2.imread(image_name)\n",
    "    #test_img = image.load_img(image_name, target_size=(150, 150))\n",
    "    #test_img = image.img_to_array(test_img)\n",
    "    feature_list_of_img = extract_features([test_img])\n",
    "    result = svc.predict(feature_list_of_img)    \n",
    "    #Displaying the output\n",
    "    if result[0] == 'Stone':\n",
    "        label.configure(text = \"Kidney Stone Detected\")\n",
    "    elif result[0] == 'Normal':\n",
    "        label.configure(text = \"No Kidney Stone Detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e2314ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Junaid Ali\\AppData\\Local\\Temp\\ipykernel_2536\\2586483366.py:10: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((200, 200), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Creating the GUI\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "import customtkinter\n",
    "import tkinter\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from tkinter import messagebox\n",
    "import keras.utils as image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "customtkinter.set_appearance_mode(\"System\")\n",
    "root = customtkinter.CTk()\n",
    "\n",
    "#window size\n",
    "root.rowconfigure(0,weight=1)    \n",
    "root.columnconfigure(0,weight=1)\n",
    "\n",
    "root.geometry('420x380')\n",
    "root.title('Kidney Stone Detection')\n",
    "        \n",
    "# Browse Button\n",
    "browsebtn = customtkinter.CTkButton(master=root, text=\"Browse Image\", command=browse_btn)\n",
    "browsebtn.grid(row=0, column=0,sticky='nw',padx=20,pady=20)\n",
    "\n",
    "\n",
    "# Predict Butoon CNN\n",
    "predictbtn = customtkinter.CTkButton(master=root, text=\"Predict CNN\", command=predict_btn_cnn)\n",
    "predictbtn.grid(row=1, column=0,sticky='nw',padx=20,pady=20)\n",
    "\n",
    "#Label Result CNN\n",
    "label_cnn = customtkinter.CTkLabel(root, text=\"\")\n",
    "label_cnn.grid(row=1,column=1,sticky='nw',padx=20,pady=20)\n",
    "\n",
    "#Label Result SVM\n",
    "label = customtkinter.CTkLabel(root, text=\"\")\n",
    "label.grid(row=2,column=1,sticky='nw',padx=20,pady=20)\n",
    "# Predict Butoon SVM\n",
    "predictbtnsvm = customtkinter.CTkButton(master=root, text=\"Predict SVM\", command=predict_btn_svm)\n",
    "predictbtnsvm.grid(row=2, column=0,sticky='nw',padx=20,pady=20)\n",
    "\n",
    "# Running the GUI\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4cfc51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
